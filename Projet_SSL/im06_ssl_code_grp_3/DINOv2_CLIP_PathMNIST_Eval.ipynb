{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abaedef",
   "metadata": {},
   "source": [
    "# PathMNIST Few‑Shot Benchmark\n",
    "\n",
    "This notebook reproduces a simple few‑shot benchmark on the **PathMNIST** histology dataset\n",
    "using image embeddings extracted from either:\n",
    "\n",
    "* **DINOv2 ViT‑L/14**\n",
    "* **OpenAI CLIP ViT‑B/16**\n",
    "\n",
    "For each backbone we train a multinomial Logistic Regression on varying fractions of\n",
    "labeled data (1 % → 100 %) and report accuracy on the held‑out test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa87bb",
   "metadata": {},
   "source": [
    "## Imports & Global Configuration\n",
    "\n",
    "All necessary libraries, constants, and the global random‐seed helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import warnings, logging, argparse, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from medmnist import PathMNIST\n",
    "import clip  # OpenAI CLIP\n",
    "\n",
    "warnings.filterwarnings('ignore', message='xFormers is available*')\n",
    "\n",
    "DEVICE = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "SEED = 42\n",
    "\n",
    "LABEL_PERCENTS = (0.01, 0.05, 0.10, 0.20, 0.50, 1.00) # Percentages of labeled data to use\n",
    "\n",
    "def set_seed(seed: int = SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a277a",
   "metadata": {},
   "source": [
    "## Logger Utility\n",
    "\n",
    "A tiny helper to get a **consistent log format** throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff2c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(name: str = 'PathMNIST'):\n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(logging.INFO)\n",
    "        h = logging.StreamHandler()\n",
    "        h.setFormatter(logging.Formatter('[%(levelname)s] %(message)s'))\n",
    "        logger.addHandler(h)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a7d97",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "Functions that download **PathMNIST**, apply image transforms, and wrap them in a `TensorDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ead648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transform():\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Resize((224, 224)),\n",
    "        T.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "\n",
    "def load_pathmnist(split: str, transform: T.Compose | None = None) -> TensorDataset:\n",
    "    data = PathMNIST(split=split, download=True)\n",
    "    imgs, labels = data.imgs, data.labels.flatten()\n",
    "    transform = transform or default_transform()\n",
    "    tensors = torch.stack([transform(Image.fromarray(im)) for im in tqdm(imgs, desc=f'Transform {split}')])\n",
    "    labels = torch.as_tensor(labels, dtype=torch.long)\n",
    "    LOGGER.info('✓ %s split ready (%d samples)', split, len(tensors))\n",
    "    return TensorDataset(tensors, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8d268",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Helper that feeds images through the chosen backbone and returns NumPy arrays of embeddings & labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd74b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model: nn.Module, dataset: TensorDataset,\n",
    "                     batch_size: int = BATCH_SIZE) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval().to(DEVICE)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, num_workers=NUM_WORKERS)\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(loader, desc='→ Extract'):\n",
    "            xb = xb.to(DEVICE)\n",
    "            with torch.autocast(device_type=DEVICE):\n",
    "                feats.append(model(xb).cpu())\n",
    "            labels.append(yb)\n",
    "    return torch.cat(feats).numpy(), torch.cat(labels).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92563c25",
   "metadata": {},
   "source": [
    "## Few‑shot Evaluation with Logistic Regression\n",
    "\n",
    "Train a multinomial Logistic Regression on different label budgets and report performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae3568f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_logreg(X_all: np.ndarray, y_all: np.ndarray,\n",
    "                     X_test: np.ndarray, y_test: np.ndarray,\n",
    "                     hp_space: Dict[float, Dict]) -> List[Tuple[float, float, float]]:\n",
    "    results = []\n",
    "    for pct in LABEL_PERCENTS:\n",
    "        LOGGER.info('-- %.0f%% labels', pct*100)\n",
    "        if pct < 1.0:\n",
    "            sss = StratifiedShuffleSplit(1, train_size=pct, random_state=SEED)\n",
    "            train_idx, _ = next(sss.split(X_all, y_all))\n",
    "        else:\n",
    "            train_idx = np.arange(len(X_all))\n",
    "        X_tr, y_tr = X_all[train_idx], y_all[train_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_tr.astype(np.float32))\n",
    "        X_ts = scaler.transform(X_test.astype(np.float32))\n",
    "\n",
    "        clf = LogisticRegression(max_iter=3000, tol=1e-2, **hp_space[pct])\n",
    "        clf.fit(X_tr, y_tr.ravel())\n",
    "\n",
    "        train_acc = accuracy_score(y_tr, clf.predict(X_tr))\n",
    "        test_acc = accuracy_score(y_test, clf.predict(X_ts))\n",
    "        LOGGER.info('train=%.4f | test=%.4f', train_acc, test_acc)\n",
    "        results.append((pct, train_acc, test_acc))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c0563",
   "metadata": {},
   "source": [
    "## Hyper‑parameters\n",
    "\n",
    "Fixed hyper‑parameters found by manual tuning for each label percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6f506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PARAMS_DINO = {\n",
    "    0.01: {'C':1.0,'penalty':'elasticnet','solver':'saga','l1_ratio':0.5},\n",
    "    0.05: {'C':0.1,'penalty':'l2','solver':'saga'},\n",
    "    0.10: {'C':0.1,'penalty':'l2','solver':'saga'},\n",
    "    0.20: {'C':0.1,'penalty':'l2','solver':'saga'},\n",
    "    0.50: {'C':0.1,'penalty':'l2','solver':'saga'},\n",
    "    1.00: {'C':1.0,'penalty':'elasticnet','solver':'saga','l1_ratio':0.5},\n",
    "}\n",
    "\n",
    "BEST_PARAMS_CLIP = {\n",
    "    0.01: {'C':0.1,'penalty':'l2','solver':'saga'},\n",
    "    0.05: {'C':1.0,'penalty':'l2','solver':'saga'},\n",
    "    0.10: {'C':1.0,'penalty':'elasticnet','solver':'saga','l1_ratio':0.5},\n",
    "    0.20: {'C':1.0,'penalty':'l2','solver':'saga'},\n",
    "    0.50: {'C':1.0,'penalty':'l2','solver':'saga'},\n",
    "    1.00: {'C':1.0,'penalty':'l2','solver':'saga'},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2020be",
   "metadata": {},
   "source": [
    "## Evaluate DINOv2 Backbone\n",
    "\n",
    "Extract embeddings with **DINOv2 ViT‑L/14** and run the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b49da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transform train: 100%|██████████| 89996/89996 [02:07<00:00, 706.41it/s] \n",
      "[INFO] ✓ train split ready (89996 samples)\n",
      "Transform test: 100%|██████████| 7180/7180 [00:09<00:00, 740.29it/s] \n",
      "[INFO] ✓ test split ready (7180 samples)\n",
      "Using cache found in /home/infres/mmohamed-22/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "[INFO] Extracting DINOv2 features …\n",
      "→ Extract: 100%|██████████| 704/704 [05:38<00:00,  2.08it/s]\n",
      "→ Extract: 100%|██████████| 57/57 [00:40<00:00,  1.40it/s]\n",
      "[INFO] Benchmarking Logistic Regression …\n",
      "[INFO] -- 1% labels\n",
      "[INFO] train=0.9944 | test=0.8623\n",
      "[INFO] -- 5% labels\n",
      "[INFO] train=0.9860 | test=0.8876\n",
      "[INFO] -- 10% labels\n",
      "[INFO] train=0.9821 | test=0.8891\n",
      "[INFO] -- 20% labels\n",
      "[INFO] train=0.9750 | test=0.8937\n",
      "[INFO] -- 50% labels\n",
      "[INFO] train=0.9680 | test=0.9015\n",
      "[INFO] -- 100% labels\n",
      "[INFO] train=0.9664 | test=0.9001\n"
     ]
    }
   ],
   "source": [
    "# ————————————— DINOv2 backbone —————————————\n",
    "transform = default_transform()\n",
    "train_ds = load_pathmnist('train', transform)\n",
    "test_ds  = load_pathmnist('test' , transform)\n",
    "\n",
    "dino_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14', trust_repo=True)\n",
    "\n",
    "LOGGER.info('Extracting DINOv2 features …')\n",
    "X_tr_dino, y_tr_dino = extract_features(dino_model, train_ds)\n",
    "X_te_dino, y_te_dino = extract_features(dino_model, test_ds)\n",
    "\n",
    "LOGGER.info('Benchmarking Logistic Regression …')\n",
    "results_dino = benchmark_logreg(X_tr_dino, y_tr_dino, X_te_dino, y_te_dino, BEST_PARAMS_DINO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb94ef5",
   "metadata": {},
   "source": [
    "## Evaluate CLIP Backbone\n",
    "\n",
    "Repeat the process with **OpenAI CLIP ViT‑B/16**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fed2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_PERCENTS = (0.01, 0.20, 0.50) # Percentages of labeled data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f3256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transform train: 100%|██████████| 89996/89996 [04:16<00:00, 350.44it/s]\n",
      "[INFO] ✓ train split ready (89996 samples)\n",
      "Transform test: 100%|██████████| 7180/7180 [00:23<00:00, 301.72it/s]\n",
      "[INFO] ✓ test split ready (7180 samples)\n",
      "[INFO] Extracting CLIP features …\n",
      "→ Extract: 100%|██████████| 704/704 [02:50<00:00,  4.13it/s]\n",
      "→ Extract: 100%|██████████| 57/57 [00:33<00:00,  1.72it/s]\n",
      "[INFO] Benchmarking Logistic Regression …\n",
      "[INFO] -- 1% labels\n",
      "[INFO] train=0.9722 | test=0.8606\n",
      "[INFO] -- 20% labels\n",
      "[INFO] train=0.9548 | test=0.8921\n",
      "[INFO] -- 50% labels\n",
      "[INFO] train=0.9502 | test=0.8923\n"
     ]
    }
   ],
   "source": [
    "# ————————————— CLIP backbone —————————————\n",
    "clip_model, preprocess_clip = clip.load('ViT-B/16', device=DEVICE)\n",
    "\n",
    "train_ds_clip = load_pathmnist('train', preprocess_clip)\n",
    "test_ds_clip  = load_pathmnist('test' , preprocess_clip)\n",
    "\n",
    "class CLIPWrapper(nn.Module):\n",
    "    def __init__(self, model): super().__init__(); self.m = model\n",
    "    def forward(self, x): return self.m.encode_image(x)\n",
    "\n",
    "clip_wrapper = CLIPWrapper(clip_model)\n",
    "\n",
    "LOGGER.info('Extracting CLIP features …')\n",
    "X_tr_clip, y_tr_clip = extract_features(clip_wrapper, train_ds_clip)\n",
    "X_te_clip, y_te_clip = extract_features(clip_wrapper, test_ds_clip)\n",
    "\n",
    "LOGGER.info('Benchmarking Logistic Regression …')\n",
    "results_clip = benchmark_logreg(X_tr_clip, y_tr_clip, X_te_clip, y_te_clip, BEST_PARAMS_CLIP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3d22a",
   "metadata": {},
   "source": [
    "## Compare Results\n",
    "\n",
    "Combine the two result lists into a single DataFrame for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a2ca6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">DINOv2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CLIP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>pct</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>pct</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994438</td>\n",
       "      <td>0.862256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.972191</td>\n",
       "      <td>0.860585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.985997</td>\n",
       "      <td>0.887604</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.954831</td>\n",
       "      <td>0.892061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.982109</td>\n",
       "      <td>0.889136</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.950153</td>\n",
       "      <td>0.892340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.974999</td>\n",
       "      <td>0.893733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.967954</td>\n",
       "      <td>0.901532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.900139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DINOv2                      CLIP                    \n",
       "     pct train_acc  test_acc   pct train_acc  test_acc\n",
       "0   0.01  0.994438  0.862256  0.01  0.972191  0.860585\n",
       "1   0.05  0.985997  0.887604  0.20  0.954831  0.892061\n",
       "2   0.10  0.982109  0.889136  0.50  0.950153  0.892340\n",
       "3   0.20  0.974999  0.893733   NaN       NaN       NaN\n",
       "4   0.50  0.967954  0.901532   NaN       NaN       NaN\n",
       "5   1.00  0.966387  0.900139   NaN       NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_dino = pd.DataFrame(results_dino, columns=['pct','train_acc','test_acc'])\n",
    "df_clip = pd.DataFrame(results_clip, columns=['pct','train_acc','test_acc'])\n",
    "\n",
    "display(pd.concat({'DINOv2':df_dino,'CLIP':df_clip}, axis=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
